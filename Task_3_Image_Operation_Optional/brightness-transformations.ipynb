{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7079b7f",
   "metadata": {},
   "source": [
    "# Init"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edbffa7",
   "metadata": {},
   "source": [
    "This notebook approximately follows the structure and adopts the notation of chapter 3 of [Burger & Burge: Digital Image Processing][1]\n",
    "\n",
    "[1]: https://link.springer.com/book/10.1007/978-1-4471-6684-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac15df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable, Union\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "import skimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64849f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9427f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.imread('data/rentgen.bmp')[..., ::-1]\n",
    "rgb.dtype, rgb.shape, rgb.min(), rgb.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(rgb, cv2.COLOR_RGB2GRAY)\n",
    "gray.dtype, gray.shape, gray.min(), gray.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c6cf1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow_pair(\n",
    "        horizontal: bool = True,\n",
    "        cmap: str = 'gray',\n",
    "        vmin: Union[int, float] = 0,\n",
    "        vmax: Union[int, float] = 255,\n",
    "        grid: bool = False,\n",
    "        **images\n",
    "):\n",
    "    nrows, ncols = (1, 2) if horizontal else (2, 1)\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, layout='constrained')\n",
    "    for ax, (name, img) in zip(axes.flat, images.items()):\n",
    "        im = ax.imshow(img, cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "        ax.grid(grid)\n",
    "        ax.set_title(name)\n",
    "    return fig, axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a696ae47",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(rgb=rgb, gray=gray);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e890b6f",
   "metadata": {},
   "source": [
    "# Brightness transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47875135",
   "metadata": {},
   "source": [
    "In general, brightness transformation is\n",
    "$$\n",
    "I'(x, y) = f(I(x, y), x, y)\n",
    "$$\n",
    "where\n",
    "- $I(x, y)$ is the original image,\n",
    "- $f$ is a transformation function,\n",
    "- $I'(x, y)$ is the newly produced transformed image.\n",
    "\n",
    "Notice that the output value $a' = I'(x, y)$ at position $(x, y)$ only depends on input value $a = I(x, y)$ at the same coordinates $(x, y)$. This means that\n",
    "**brightness transformations do not change size, geometry or local structure of the image**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5840e472",
   "metadata": {},
   "source": [
    "# Monadic operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb748d3",
   "metadata": {},
   "source": [
    "A special category of brightness transformations are monadic (unary, single input) operations, which are independent of the position $(x, y)$ in the image.\n",
    "$$\n",
    "a' = f(I(x, y)) = f(a)\n",
    "$$\n",
    "where\n",
    "- $a = I(x, y)$ is the original brightness,\n",
    "- $a' = I'(x, y)$ the transformed brightness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f279ae6",
   "metadata": {},
   "source": [
    "## Change of brightness\n",
    "\n",
    "**Manipulating brightness has an additive effect:**\n",
    "$$\n",
    "f(a) = a + \\beta\n",
    "$$\n",
    "For example, to increase the brightness by 10, we would do $f(a) = a + 10$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9008a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_brightness(img: np.ndarray, beta: float) -> np.ndarray:\n",
    "    height, width = img.shape\n",
    "    output = np.zeros_like(img)\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            b = img[y, x] + beta\n",
    "            if b > 255:\n",
    "                b = 255\n",
    "            output[y, x] = b\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "266ad579",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_brt = change_brightness(gray, 50)\n",
    "gray_brt.dtype, gray_brt.shape, gray_brt.min(), gray_brt.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ab77ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_brt=gray_brt);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea05514",
   "metadata": {},
   "source": [
    "## Change of contrast\n",
    "\n",
    "**Manipulating contrast has a multiplicative effect:**\n",
    "$$\n",
    "f(a) = \\alpha \\cdot a\n",
    "$$\n",
    "For example, to increase the contrast by 50 %, we would do $f(a) = 1.5\\cdot a$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0b4d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_contrast(img: np.ndarray, alpha: float) -> np.ndarray:\n",
    "    height, width = img.shape\n",
    "    output = np.zeros_like(img)\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            output[y, x] = img[y, x] * alpha  # FIXME: a problem here\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dde7cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_con = change_contrast(gray, 1.5)\n",
    "gray_con.dtype, gray_con.shape, gray_con.min(), gray_con.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9afde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_con=gray_con);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feeaad36",
   "metadata": {},
   "source": [
    "# Inverting an image (image negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8aeb3ce",
   "metadata": {},
   "source": [
    "The transformation function is\n",
    "$$f(a) = a_\\textrm{max} - a$$\n",
    "For `uint8`, $a_\\textrm{max} = 255$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c70dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_negative_slow(img: np.ndarray, v_max: int = 255) -> np.ndarray:\n",
    "    height, width = img.shape\n",
    "    output = np.zeros_like(img)\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            output[y, x] = v_max - img[y, x]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cec7ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_neg = image_negative_slow(gray)\n",
    "gray_neg.dtype, gray_neg.shape, gray_neg.min(), gray_neg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd96b80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_neg=gray_neg);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfb3434",
   "metadata": {},
   "source": [
    "## Fast vectorized implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d744688a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_negative(img: np.ndarray, v_max: int = 255) -> np.ndarray:\n",
    "    return v_max - img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d797d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_neg = image_negative(gray)\n",
    "gray_neg.dtype, gray_neg.shape, gray_neg.min(), gray_neg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85532d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_neg=gray_neg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc62aba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit image_negative_slow(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e903d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit image_negative(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214ace43",
   "metadata": {},
   "source": [
    "# Thresholding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11177959",
   "metadata": {},
   "source": [
    "Thresholding is a brightness transformation function that separates pixels by their value into two classes, for example background and foreground.\n",
    "$$\n",
    "f(a; t) = \\begin{cases}\n",
    "    a_\\textrm{min} & \\textrm{if} \\; a \\lt t \\\\\n",
    "    a_\\textrm{max} & \\textrm{if} \\; a \\ge t\n",
    "\\end{cases}\n",
    "$$\n",
    "where\n",
    "- $t$ is some threshold value.\n",
    "\n",
    "Usually, we want to *binarize* the image and therefore choose $a_\\textrm{min} = 0$ and $a_\\textrm{max} = 1$ (or sometimes 0 and 255 in case of `uint8` images)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1281ab3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_image(img: np.ndarray, threshold: int, v_max: int = 255) -> np.ndarray:\n",
    "    output = np.zeros_like(img)\n",
    "    output[img >= threshold] = v_max\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d23697c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_thr = threshold_image(gray, 125)\n",
    "gray_thr.dtype, gray_thr.shape, gray_thr.min(), gray_thr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb379de",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_thr=gray_thr);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed8098b",
   "metadata": {},
   "source": [
    "# Automatic contrast adjustment (enhancement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40fe32a5",
   "metadata": {},
   "source": [
    "Let's first look at the image histogram:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117e502d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_bins = np.arange(257)\n",
    "h_gray, _ = np.histogram(gray, bins=h_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e572480",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(h_bins[:-1], h_gray, width=1., edgecolor='none');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb89988",
   "metadata": {},
   "source": [
    "If the image only covers a small range of intensities, it may appear as low contrast. In order to increase the contrast, we need to fully utilize the entire range of possible intensities like in the following picture.\n",
    "\n",
    "<img src=\"figures/brightness_transformations-auto_contrast_adjust.png\" alt=\"Drawing\" style=\"width: 6in;\"/>\n",
    "\n",
    "Let's say the smallest and the highest values in our image $I$ are $a_\\textrm{lo} = \\min(I)$ and $a_\\textrm{hi} = \\max(I)$, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8ea09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray.min(), gray.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62265497",
   "metadata": {},
   "source": [
    "In order to cover some specified brightness range, we will map the smallest value $a_\\textrm{lo}$ to zero (let's call that zero $a_\\textrm{min}$) and the highest value $a_\\textrm{hi}$ to 255 ($=a_\\textrm{max}$) like so\n",
    "$$\n",
    "f(a) = \\frac{a_\\textrm{max} - a_\\textrm{min}}{a_\\textrm{hi} - a_\\textrm{lo}} \\cdot (a - a_\\textrm{lo}) + a_\\textrm{min}\n",
    "$$\n",
    "which for an 8-bit with $a_\\textrm{min} = 0$ and $a_\\textrm{max} = 255$ simplifies to\n",
    "$$\n",
    "f(a) = \\frac{255}{a_\\textrm{hi} - a_\\textrm{lo}} \\cdot (a - a_\\textrm{lo})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01085a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_minmax_uint8(img: np.ndarray) -> np.ndarray:\n",
    "    a_lo, a_hi = img.min(), img.max()\n",
    "    output = 255. / (a_hi - a_lo) * (img - a_lo)\n",
    "    return output.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaebc34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_nrm = normalize_minmax_uint8(gray)\n",
    "gray_nrm.dtype, gray_nrm.shape, gray_nrm.min(), gray_nrm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584b010b",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_nrm=gray_nrm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb15b983",
   "metadata": {},
   "source": [
    "# Automatic contrast adjustment for noisy images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc84aac5",
   "metadata": {},
   "source": [
    "Simple min-max normalization will fail when there are outlier values in the input image. Let's corrupt our image with artificial salt & pepper noise to illustrate the point. Each pixel will be randomly set to 0 or 255 with some probability (`amount` in the following code)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480b96f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_snp = skimage.util.random_noise(gray, mode='s&p', amount=0.01)  # this also converts to float and 0..1 range\n",
    "gray_snp = skimage.util.img_as_ubyte(gray_snp)  # convert back to uint8 and 0..255\n",
    "gray_snp.dtype, gray_snp.shape, gray_snp.min(), gray_snp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b315418",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_snp=gray_snp);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0267d49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(gray_snp.ravel(), bins=h_bins, width=1., edgecolor='none');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b50973",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_snp_nrm = normalize_minmax_uint8(gray_snp)\n",
    "gray_snp_nrm.dtype, gray_snp_nrm.shape, gray_snp_nrm.min(), gray_snp_nrm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f08547",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray_snp=gray_snp, gray_snp_nrm=gray_snp_nrm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f301916",
   "metadata": {},
   "source": [
    "Obviously, because the original brightness values already covered the entire `uint8` range 0..255 due to the added noise, there was nothing to \"stretch\". In order to remedy this, we need to estimate the original brightness range *before* the noise corruption. One idea is to assume the type of noise (salt & pepper) and the maximum amount (5 % in our case). Then, insted of hard max, we can set $a_\\textrm{hi}$ to be a value such that 95 % of pixels in the image are smaller, and similarly set the $a_\\textrm{lo}$ as well. See the following illustration, where the percentage of pixels with the few lowest and highest values are denoted as $p_\\textrm{lo}$ and $p_\\textrm{hi}$, respectively.\n",
    "\n",
    "<img src=\"figures/brightness_transformations-percentile_contrast_adjustment.png\" alt=\"Drawing\" style=\"width: 6in;\"/>\n",
    "\n",
    "Both values $a_\\textrm{lo}$, $a_\\textrm{hi}$ can be calculated using the `np.percentile` function. However, will do so manually using a cumulative histogram, since the `np.percentile` relies on cumulative distribution function anyway and it will be useful later for implementation of histogram equalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca24325b",
   "metadata": {},
   "source": [
    "## Cumulative histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f840fc54",
   "metadata": {},
   "source": [
    "If we have a histogram $h$ of our image $I$, the cumulative histogram $H$ is defined as\n",
    "$$\n",
    "H(a) = \\sum_{i=0}^i h(i) \\quad \\textrm{for} \\; 0 \\le a \\lt K\n",
    "$$\n",
    "where\n",
    "- $K$ is the number of brightness levels, e.g. $K = 256$ for `uint8` images.\n",
    "\n",
    "It holds that\n",
    "- $a$-th value in $H$ is the sum of all values in $h$ up to the $a$-th position,\n",
    "- the last element $H(K-1)$ is equal to the number of pixels in $I$. If $M$ and $N$ are the width and height of $I$, respectively, then $H(K-1) = M \\cdot N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b47156d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_naive(h: np.ndarray) -> np.ndarray:\n",
    "    H = np.zeros_like(h)\n",
    "    for a in range(len(h)):\n",
    "        for i in range(a+1):\n",
    "            H[a] += h[i]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0d92b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cumsum_recursive(h: np.ndarray) -> np.ndarray:\n",
    "    H = np.zeros_like(h)\n",
    "    H[0] = h[0]\n",
    "    for i in range(2, len(h)):\n",
    "        H[i] = H[i - 1] + h[i]\n",
    "    return H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5d8e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(cumsum_naive(h_gray) == cumsum_recursive(h_gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e58aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cumsum_naive(h_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24e87e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit cumsum_recursive(h_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cf83988",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.all(np.cumsum(h_gray) == cumsum_recursive(h_gray))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48827cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit np.cumsum(h_gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b44b36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_gray_cum = np.cumsum(h_gray)\n",
    "h_gray_cum.dtype, h_gray_cum.shape, h_gray_cum.min(), h_gray_cum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cd3b21",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.bar(h_bins[:256], h_gray, width=1, alpha=0.2)\n",
    "plt.xlabel('$a$')\n",
    "plt.ylabel('$h(a)$')\n",
    "plt.gca().twinx()\n",
    "plt.plot(h_gray_cum)\n",
    "plt.ylabel('$H(a)$')\n",
    "plt.ylim(-1000., None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca02119",
   "metadata": {},
   "source": [
    "## Frequencies and probabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd27be3",
   "metadata": {},
   "source": [
    "The value in each histogram bin describes the observed frequency of the corresponding intensity value, i.e. we may treat the histogram as a discrete *frequency distribution*. For a given image $I$ of size $M \\times N$, the sum of all histogram entries is equal to the number of pixels\n",
    "$$\n",
    "\\sum_a{h(a)} = M \\cdot N\n",
    "$$\n",
    "\n",
    "The associated normalized histogram\n",
    "$$\n",
    "p(a) = \\frac{h(a)}{M \\cdot N}\n",
    "$$\n",
    "can be interpreted as the probability mass function (pmf), where $p(a)$ is the probability for the occurence of the pixel value $a$. As a probability distribution, it satisfies\n",
    "$$\n",
    "\\sum_a{p(a)} = 1\n",
    "$$\n",
    "The statistical counterpart to the cumulative histogram $H$ is the *cumulative distribution function*\n",
    "$$\n",
    "\\textrm{cdf}(a) = \\sum_{i=0}^a{p(i)} = \\frac{H(a)}{M \\cdot N}\n",
    "$$\n",
    "Each value $\\textrm{cdf}(a)$ tells us the percentile of $a$. If, for example, $\\textrm{cdf}(10) = 0.07$, it means that 7 % of pixels in the image $I$ have a value smaller or equal to $10$. The last value $\\textrm{cdf}(K-1)$ (typically $K=256$ for `uint8` images) is always equal to one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c79a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pmf(h: np.ndarray) -> np.ndarray:\n",
    "    return h / h.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1410a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gray = pmf(h_gray)\n",
    "p_gray.shape, p_gray.dtype, p_gray.min(), p_gray.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437469d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cdf(h: np.ndarray) -> np.ndarray:\n",
    "    p_cum = np.cumsum(h)\n",
    "    return p_cum / p_cum[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cfe9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_gray_cum = cdf(h_gray)\n",
    "p_gray_cum.shape, p_gray_cum.dtype, p_gray_cum.min(), p_gray_cum.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0c78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    plt.bar(h_bins[:256], p_gray, width=1., alpha=0.2)\n",
    "    plt.xlabel('$a$')\n",
    "    plt.ylabel('$p(a)$')\n",
    "    plt.gca().twinx()\n",
    "    plt.plot(p_gray_cum)\n",
    "    plt.ylabel('$\\\\text{cdf}(a)$')\n",
    "    plt.ylim(-0.01, None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24941908",
   "metadata": {},
   "source": [
    "## Normalization range limits $a_\\textrm{lo}$ and $a_\\textrm{hi}$ as percentiles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf7436e",
   "metadata": {},
   "source": [
    "Using cumulative distribution function $\\textrm{cdf}$, we can easily find brightness values $a_\\textrm{lo}$ and $a_\\textrm{hi}$, which correspond to the smallest and largest few percent of values in $I$, respectively. The value $a_\\textrm{lo}$ will be the first entry in the $\\textrm{cdf}$ which is larger than e.g. 5 %. If we denote the percentage as $p_\\textrm{lo}$, then\n",
    "$$\n",
    "a_\\textrm{lo} = \\min\\left\\{a | \\textrm{cdf}(a) \\ge p_\\textrm{lo}\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab469f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_lo = next(a for a in range(len(h_gray_cum)) if p_gray_cum[a] >= 0.05)  # p_lo = 0.05\n",
    "a_lo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f94180e9",
   "metadata": {},
   "source": [
    "Similarly, $a_\\textrm{hi}$ will be the last $a$ for which $\\textrm{cdf}(a) \\le 0.95$, i.e.\n",
    "$$\n",
    "a_\\textrm{hi} = \\max\\left\\{a | \\textrm{cdf}(a) \\le (1 - p_\\textrm{hi})\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "172e166f",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hi = next(a for a in reversed(range(len(h_gray_cum))) if p_gray_cum[a] <= 0.95)  # p_hi = 0.05\n",
    "a_hi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0abb0a3",
   "metadata": {},
   "source": [
    "Let's put the entire percentile-based contrast adjustment into single function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc804f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_percentile_uint8(img: np.ndarray, percentage: float = 0.05) -> np.ndarray:\n",
    "    h, _ = np.histogram(img.ravel(), bins=np.arange(257))\n",
    "    p_cum = cdf(h)\n",
    "    a_lo = next(a for a in range(len(p_cum)) if p_cum[a] > percentage)\n",
    "    a_hi = next(a for a in reversed(range(len(p_cum))) if p_cum[a] < 1. - percentage)\n",
    "    output = 255. / (a_hi - a_lo) * (img.astype(float) - a_lo)\n",
    "    return output.clip(min=0, max=255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c34923",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_snp_nrp = normalize_percentile_uint8(gray_snp, percentage=0.05)  # try lowering percentile here\n",
    "gray_snp_nrp.dtype, gray_snp_nrp.shape, gray_snp_nrp.min(), gray_snp_nrp.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a059f1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray_snp=gray_snp, gray_snp_nrp=gray_snp_nrp);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4971d305-aa1d-495c-97bc-8aa0a0baf822",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Brightness transformations as an application of the function $f$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e50d097",
   "metadata": {},
   "source": [
    "Notice that in all of the examples above, the procedure for transforming the input image using a monadic transformation function $f$ was always the same. The only thing that varied was the function $f$. Therefore, we may create a general function `remap_values` that takes in two inputs: image and $f$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b07e341",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_values(img: np.ndarray, f: Callable[[float], float]) -> np.ndarray:\n",
    "    height, width = img.shape\n",
    "    output = np.zeros_like(img)\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            output[y, x] = f(img[y, x])\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14538ab",
   "metadata": {},
   "source": [
    "## Inverting an image (image negative)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b664ca24",
   "metadata": {},
   "source": [
    "We'll look at image negative again. However this time, we will do it using the `remap_values` function. Remember that the image negative transformation function is\n",
    "$$f(a) = a_\\textrm{max} - a$$\n",
    "For `uint8`, $a_\\textrm{max} = 255$. Let's create $f$ as a Python function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4c51197",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f_neg(a: float) -> float:\n",
    "    return 255 - a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a82841e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_neg = remap_values(gray, f_neg)\n",
    "gray_neg.dtype, gray_neg.shape, gray_neg.min(), gray_neg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de186da",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_neg=gray_neg);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe9184a",
   "metadata": {},
   "source": [
    "## Pre-computing $f$ as a lookup table (LUT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d6873a",
   "metadata": {},
   "source": [
    "When we are working with discrete images with finite number of distinct pixel values, the transformation function $f(a)$ will be a discrete function with a finite number of distinct values of $a$. Typically, for `uint8`, $a = 0,\\ldots,255$. We may then pre-compute the output values $f(a)$ so that $f$ need not to be re-evaluated for each pixel inside the for loop of `transform_values`. We'll create another function `transform_values_uint8`, in which the second argument will be a vector of size 256 with pre-computed values of $f$ instead of $f$ itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b2d406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remap_values_uint8(img: np.ndarray, f_lut: np.ndarray) -> np.ndarray:\n",
    "    height, width = img.shape\n",
    "    output = np.zeros_like(img)\n",
    "    for y in range(height):\n",
    "        for x in range(width):\n",
    "            output[y, x] = f_lut[img[y, x]]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_negative_lut() -> np.ndarray:\n",
    "    return 255 - np.arange(256, dtype=np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a97c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_neg = create_image_negative_lut()\n",
    "lut_neg.shape, lut_neg.dtype, lut_neg.min(), lut_neg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b93e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_lut(lut: np.ndarray):\n",
    "    plt.plot(lut);\n",
    "    plt.xlabel('$a$')\n",
    "    plt.ylabel('$a\\'$')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f933a916",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lut(lut_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4c580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_neg = remap_values_uint8(gray, lut_neg)\n",
    "gray_neg.dtype, gray_neg.shape, gray_neg.min(), gray_neg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85615f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_neg=gray_neg);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2cc7f05",
   "metadata": {},
   "source": [
    "We can verify that the LUT approach is significantly faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b300e8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit remap_values(gray, f_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe9d645",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit remap_values_uint8(gray, lut_neg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7909b4f3",
   "metadata": {},
   "source": [
    "Moreover, we can take advantage of highly optimized Numpy indexing and speed up the transformation even further."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fb3aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_neg = lut_neg[gray]\n",
    "gray_neg.dtype, gray_neg.shape, gray_neg.min(), gray_neg.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83f71c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_neg=gray_neg);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8a0617",
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit lut_neg[gray]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ef7a63",
   "metadata": {},
   "source": [
    "## Thresholding via LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10dbb7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_thresholding_lut(threshold: int) -> np.ndarray:\n",
    "    lut = np.zeros(256, dtype=np.uint8)\n",
    "    lut[threshold:] = 255\n",
    "    return lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1919d7-2f2a-4623-9e84-373e2eeff3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_thr = create_thresholding_lut(125)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757b0365",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lut(lut_thr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edaaa34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_thr = lut_thr[gray]\n",
    "gray_thr.dtype, gray_thr.shape, gray_thr.min(), gray_thr.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e992452f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_thr=gray_thr);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2691a2b9",
   "metadata": {},
   "source": [
    "## Contrast adjustment via LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca5750df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_contrast_adjustment_lut(a_lo: int, a_hi: int, a_min: int, a_max: int) -> np.ndarray:\n",
    "    lut = (a_max - a_min) / (a_hi - a_lo) * (np.arange(256, dtype=float) - a_lo) + a_min\n",
    "    return lut.clip(0, 255).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1512c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_adj = create_contrast_adjustment_lut(a_lo, a_hi, 0, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d868e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lut(lut_adj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965ebc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_nrm = lut_adj[gray]\n",
    "gray_nrm.shape, gray_nrm.dtype, gray_nrm.min(), gray_nrm.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6eb8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray=gray, gray_nrm=gray_nrm);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a7f6c7-01c4-4c1a-b7d2-64bc3467b925",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Histogram equalization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a4eb5c",
   "metadata": {},
   "source": [
    "The goal of histogram equalization is to find a value mapping such that the histogram of the remmaped image approximates a uniform distribution. The resulting image will appear as high contrast, since all possible rightness values will be utilized in roughly the same amount.\n",
    "\n",
    "The principle is illustrated in the following figure. We are trying to find a mapping that shifts the histogam such that the resulting cumulative histogram resembles a linear ramp, i.e. like an ideal uniformly distributed image would.\n",
    "\n",
    "<img src=\"figures/brightness_transformations-cumulative_histogram.png\" alt=\"Drawing\" style=\"width: 6in;\"/>\n",
    "\n",
    "Basically, the idea is to stretch all dense clusters of similar values to be farther apart, in order to make them visually more distinct. This is similar to e.g. automatic contrast adjustment, but equalization remaps the values non-linearly based on local histogram density\n",
    "\n",
    "The desired operation is obtained from the cumulative histogram $H$ of the original image as\n",
    "$$\n",
    "f(a) = \\left\\lfloor H(a) \\cdot \\frac{K-1}{M \\cdot N} \\right\\rfloor = \\left\\lfloor \\textrm{cdf}(a) \\cdot (K-1) \\right\\rfloor\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32672991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram_equalization_lut(h: np.ndarray) -> np.ndarray:\n",
    "    h_cum = cdf(h)\n",
    "    lut = np.floor(h_cum * 255)\n",
    "    return lut.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7523a3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try histogram equalization with noisy image to demonstrate its robustness\n",
    "lut_equ = create_histogram_equalization_lut(np.histogram(gray_snp, bins=np.arange(257))[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e07c7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lut(lut_equ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4013fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_snp_equ = lut_equ[gray_snp]\n",
    "gray_snp_equ.shape, gray_snp_equ.dtype, gray_snp_equ.min(), gray_snp_equ.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdeef1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(gray_snp=gray_snp, gray_snp_equ=gray_snp_equ);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb6df72",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    plt.figure(figsize=(6.4, 2.4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.bar(h_bins[:256], h_gray, width=1., edgecolor='none')\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.bar(h_bins[:256], np.histogram(gray_snp_equ, bins=h_bins)[0], width=1., edgecolor='none')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17df70a4",
   "metadata": {},
   "source": [
    "# Histogram matching"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a549f3",
   "metadata": {},
   "source": [
    "We also may want to remap one image in such a way that the resulting histogram will aproximate a histogram of another image.\n",
    "\n",
    "<img src=\"figures/brightness_transformations-histogram_matching.png\" alt=\"Drawing\" style=\"width: 6in;\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d9765b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_histogram_match_lut(h_input: np.ndarray, h_ref: np.ndarray) -> np.ndarray:\n",
    "    cdf_input = cdf(h_input)\n",
    "    cdf_ref = cdf(h_ref)\n",
    "    lut = np.zeros(len(h_input), dtype=np.uint8)\n",
    "    for a in range(len(h_input)):\n",
    "        try:\n",
    "            lut[a] = next(i for i in reversed(range(len(h_input))) if cdf_input[a] > cdf_ref[i])\n",
    "        except StopIteration:\n",
    "            lut[a] = 0\n",
    "    return lut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24de94a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_refs = [\n",
    "    scipy.stats.beta(alpha, beta).pdf(np.linspace(0.01, 0.99, 256))\n",
    "    for alpha, beta in ((0.5, 0.5), (5., 1.), (1., 3.), (2., 2.))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9947bfce",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    for a, h_ref in enumerate(h_refs):\n",
    "        plt.subplot(2, 2, a + 1)\n",
    "        plt.bar(h_bins[:256], h_ref, width=1, edgecolor='none');\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c64bff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "lut_mchs = [\n",
    "    create_histogram_match_lut(h_gray, h_ref)\n",
    "    for h_ref in h_refs\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4ace8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    for a, lut_mch in enumerate(lut_mchs):\n",
    "        plt.subplot(2, 2, a + 1)\n",
    "        plt.plot(lut_mch);\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2e8eff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_mchs = [lut_mch[gray] for lut_mch in lut_mchs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c17fbd6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    plt.figure(figsize=(2. * plt.rcParams['figure.figsize'][0], 2. * plt.rcParams['figure.figsize'][1]))\n",
    "    for a, (h_ref, lut_mch, gray_mch) in enumerate(zip(h_refs, lut_mchs, gray_mchs)):\n",
    "        plt.subplot(4, 4, 4 * a + 1)\n",
    "        plt.bar(h_bins[:256], h_ref, edgecolor='none', width=1.)  # 1st column: target histogram\n",
    "        plt.subplot(4, 4, 4 * a + 2)\n",
    "        plt.plot(lut_mch);  # 2nd column: mapping function (LUT)\n",
    "        plt.subplot(4, 4, 4 * a + 3)\n",
    "        plt.imshow(gray_mch, cmap='gray', vmin=0, vmax=255);  # 3rd column: remapped image\n",
    "        plt.grid(False)\n",
    "        plt.subplot(4, 4, 4 * a + 4)\n",
    "        plt.bar(h_bins[:256], np.histogram(gray_mch, bins=h_bins)[0], edgecolor='none', width=1.)  # 4th column: histogram of the remapped image\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2953b914",
   "metadata": {},
   "source": [
    "# Gamma correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9130e113",
   "metadata": {},
   "source": [
    "Usually, the relationship between physical signal amplitude such as light intensity emitted by an LCD screen and its input voltage, or vice versa, charge accumulated on a camera chip and the converted intensity, is non-linear. Perhaps surprisingly, a lot of these relationships can be modeled as an exponential function of the form\n",
    "$$\n",
    "f(a) = a^\\gamma\n",
    "$$\n",
    "where\n",
    "- $\\gamma \\in \\mathbb{R}$ is a parameter called gamma value.\n",
    "\n",
    "Depending on the gamma value, the function can look like the following figure.\n",
    "\n",
    "<img src=\"figures/brightness_transformations-gamma_function.png\" alt=\"Drawing\" style=\"width: 6in;\"/>\n",
    "\n",
    "We may use $f(a)$ in a process called *gamma correction*, in which we try to linearize the input-output relationship in order to standardize stored values across different devices. See the following figure.\n",
    "\n",
    "<img src=\"figures/brightness_transformations-gamma_correction.png\" alt=\"Drawing\" style=\"width: 6in;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6749a077",
   "metadata": {},
   "source": [
    "# Comparison of brightness transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e227a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('darkgrid'):\n",
    "    fig, axes = plt.subplots(nrows=5, ncols=2, constrained_layout=True, figsize=(plt.rcParams['figure.figsize'][0], 2.5*plt.rcParams['figure.figsize'][1]))\n",
    "    for axr, lut in zip(axes, [np.arange(256), lut_adj, lut_equ, lut_thr, lut_neg]):\n",
    "        axr[0].plot(lut);\n",
    "        axr[1].imshow(lut[gray], cmap='gray', vmin=0, vmax=255)\n",
    "        axr[1].grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa4e60dc",
   "metadata": {},
   "source": [
    "# Brightness transformations dependent on position"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e20645de",
   "metadata": {},
   "source": [
    "## Vignette effect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978b88c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "rgb = cv2.imread('data/sunflowers.png')[..., ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ccefc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('dark'):\n",
    "    plt.imshow(rgb);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e199ebb",
   "metadata": {},
   "source": [
    "Create the vignette effect by calculating (axis normalized) distance from the center:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c493c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# vignette\n",
    "x, y = np.meshgrid(np.arange(rgb.shape[1]), np.arange(rgb.shape[0]))\n",
    "xc, yc = rgb.shape[1] / 2, rgb.shape[0] / 2\n",
    "dx2 = (x - xc) ** 2 / rgb.shape[1] ** 2\n",
    "dy2 = (y - yc) ** 2 / rgb.shape[0] ** 2\n",
    "vig_dist = np.clip(1.2 - np.sqrt(dx2 + dy2), 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b86e24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('dark'):\n",
    "    plt.imshow(vig_dist)\n",
    "    plt.colorbar(shrink=0.5, aspect=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385db431",
   "metadata": {},
   "source": [
    "Alternatively, we can use 2D Gaussian distribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3af9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = np.meshgrid(np.arange(rgb.shape[1]), np.arange(rgb.shape[0]))\n",
    "vig_gauss = np.clip(-1. + 2.15 * np.exp(-(x - xc) ** 2 / rgb.shape[1] ** 2 - (y - yc) ** 2 / rgb.shape[0] ** 2), 0., 1.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b214898c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with sns.axes_style('dark'):\n",
    "    plt.imshow(vig_gauss)\n",
    "    plt.colorbar(shrink=0.5, aspect=10);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4e8a0a",
   "metadata": {},
   "source": [
    "Multiply the input image `rgb` by the `vig_*` matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931dc4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel by channel\n",
    "rgb_vig = np.zeros(rgb.shape, dtype=rgb.dtype)\n",
    "for c in range(rgb.shape[2]):\n",
    "    rgb_vig[..., c] = vig_dist * rgb[..., c]\n",
    "rgb_vig.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1dd9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# broadcasting\n",
    "rgb_vig = (vig_gauss[..., None] * rgb).astype(np.uint8)\n",
    "rgb_vig.dtype, rgb_vig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567880b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow_pair(rgb=rgb, rgb_vig=rgb_vig, horizontal=False);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "5b9074e4f59d9e4c1c666e845adc4ed7aca44e3ae145b1af153cab2889089e68"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
